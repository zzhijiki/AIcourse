{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业四\n",
    "\n",
    "## 四、AdaBoost算法\n",
    "\n",
    "利用算法8.1对iris数据集进行分类\n",
    "\n",
    "* 利用sklearn提供的`DecisionTreeClassifier`构造单层决策树作为基本分类器\n",
    "* 调整式(8.7)以适用于多分类的情况\n",
    "\n",
    "ETA：0.5-3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T18:38:18.672476Z",
     "start_time": "2019-11-29T18:38:17.596414Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T18:38:18.678476Z",
     "start_time": "2019-11-29T18:38:18.673476Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_iris(ratio=0.8):\n",
    "    features, target = datasets.load_iris(True)\n",
    "    \n",
    "    num_samples = len(target)\n",
    "    num_train = math.ceil(num_samples * ratio)\n",
    "    \n",
    "    # 随机打乱数据\n",
    "    idx = np.random.permutation(np.arange(num_samples))\n",
    "    traindata = features[idx[:num_train]], target[idx[:num_train]]\n",
    "    validdata = features[idx[num_train:]], target[idx[num_train:]]\n",
    "    \n",
    "    return traindata, validdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T18:38:18.907489Z",
     "start_time": "2019-11-29T18:38:18.680476Z"
    }
   },
   "outputs": [],
   "source": [
    "class AdaBoostClassifier:\n",
    "    def __init__(self, n_estimators=50):\n",
    "        self.n_estimators = n_estimators\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "          X: array of shape (N, C)\n",
    "          y: array of shape (N, )\n",
    "        \"\"\"\n",
    "        assert len(X.shape) == 2\n",
    "        assert X.shape[0] == y.shape[0]\n",
    "        \n",
    "        self.classes_ = np.unique(y)  ##[0,1,2]\n",
    "            \n",
    "        self.estimators_ = []\n",
    "        self.estimator_weights_ = np.zeros(self.n_estimators) ###[0,0,0,*50]\n",
    "        self.estimator_errors_ = np.ones(self.n_estimators) ###[1,1,1,*50]\n",
    "        \n",
    "        self.boss=0\n",
    "        \n",
    "        num_samples = X.shape[0]  ##120\n",
    "        sample_weight = np.full((num_samples, ), 1./num_samples)  ##[1/120,1/120,1/120,*120]\n",
    "\n",
    "        for iboost in range(self.n_estimators):\n",
    "            sample_weight, estimator, estimator_weight, estimator_error = self._boost(X, y,sample_weight)\n",
    "            self.estimators_.append(estimator)\n",
    "            self.estimator_weights_[iboost] = estimator_weight## alpha_m\n",
    "            self.estimator_errors_[iboost] = estimator_error###e_m\n",
    "                            \n",
    "        return self\n",
    "            \n",
    "    def _boost(self, X, y, sample_weight):\n",
    "        estimator = DecisionTreeClassifier(max_depth=1) ##model_name\n",
    "        estimator.fit(X,y,sample_weight=sample_weight)\n",
    "        Y_pred=estimator.predict(X)\n",
    "\n",
    "        estimator_error=np.sum(sample_weight*(Y_pred!=Y_train))  ###e_m\n",
    "        sample_weight_temp=[]\n",
    "        estimator_weight=0.5*np.log((1-estimator_error+0.00001)/(estimator_error+0.00001))  ## alpha_m\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            if Y_pred[i]!=Y_train[i]:\n",
    "                sample_weight_temp.append(sample_weight[i]*np.exp(estimator_weight))\n",
    "            else:\n",
    "                sample_weight_temp.append(sample_weight[i]*np.exp(-estimator_weight))\n",
    "        Z=np.sum(sample_weight_temp)\n",
    "        sample_weight=sample_weight_temp/Z  ##D_m\n",
    "        \n",
    "        return sample_weight, estimator, estimator_weight, estimator_error\n",
    "    \n",
    "    def predict(self, X):\n",
    "        n,k=X.shape[0],len(self.classes_ )\n",
    "        G=np.zeros((n,k))\n",
    "        for iboost in range(self.n_estimators):\n",
    "            Y_pred=self.estimators_[iboost].predict_proba(X) ## 用软分类做,懒得onehot了\n",
    "            G=G+self.estimator_weights_[iboost]*Y_pred\n",
    "#         print(G)\n",
    "        pred=np.argmax(G, axis=1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T18:38:19.111501Z",
     "start_time": "2019-11-29T18:38:18.909489Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(Y_real, Y_pred):\n",
    "    return np.sum(Y_real == Y_pred)/len(Y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T18:38:19.546526Z",
     "start_time": "2019-11-29T18:38:19.112501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_valid, Y_valid) = load_iris()\n",
    "model = AdaBoostClassifier(n_estimators=50)\n",
    "model.fit(X_train, Y_train)\n",
    "accu = accuracy(model.predict(X_valid), Y_valid)\n",
    "print(f\"Accuracy: {accu:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     " ID:51185500028\n",
     "```\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}