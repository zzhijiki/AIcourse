{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training usage, you might want to add your own here\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.patheffects as PathEffects\n",
    "# from centerLoss import CenterLoss\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find an available GPU device and set it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = {\n",
    "    \"train\":\"train\",\n",
    "    \"valid\":\"valid\",\n",
    "    \"test\":\"test\"\n",
    "}\n",
    "\n",
    "def train_tf(x):\n",
    "   \n",
    "    im_aug = transforms.Compose([\n",
    "        transforms.Resize(120),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(96),\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5, hue=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    x = im_aug(x)\n",
    "    return x\n",
    "\n",
    "def test_tf(x):\n",
    "   \n",
    "    im_aug = transforms.Compose([\n",
    "        transforms.Resize(120),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    x = im_aug(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load training and validation data\n",
    "X1=ImageFolder(data_root[\"train\"],transform=train_tf)  \n",
    "X2=ImageFolder(data_root[\"valid\"],transform=test_tf)  \n",
    "\n",
    "## I mix train and valid only when I do finetune .\n",
    "## when finetune ,X1 and X2 use transform=test_tf to keep it work.\n",
    "## random seed does not work,but i still use it.\n",
    "init_seed = 1\n",
    "torch.manual_seed(init_seed)\n",
    "torch.cuda.manual_seed(init_seed)\n",
    "np.random.seed(init_seed) \n",
    "\n",
    "X=torch.utils.data.ConcatDataset([X1,X2])\n",
    "X_train,X_valid = torch.utils.data.random_split(X, [160000, 20000])\n",
    "train_dataloader= DataLoader(X_train,batch_size=64,shuffle=True)\n",
    "valid_dataloader= DataLoader(X_valid,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for loss\n",
    "class CrossEntropyLabelSmooth(nn.Module):\n",
    "    def __init__(self, num_classes, epsilon):\n",
    "        super(CrossEntropyLabelSmooth, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.epsilon = epsilon\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "    def forward(self, inputs, targets):\n",
    "        log_probs = self.logsoftmax(inputs)\n",
    "        targets = torch.zeros_like(log_probs).scatter_(1, targets.unsqueeze(1), 1)\n",
    "        targets = (1 - self.epsilon) * targets + self.epsilon / self.num_classes\n",
    "        loss = (-targets * log_probs).mean(0).sum()\n",
    "        return loss\n",
    "## for net\n",
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.extract = torch.nn.Sequential(\n",
    "            torchvision.models.resnet152(pretrained=True).conv1,\n",
    "            torchvision.models.resnet152(pretrained=True).bn1,\n",
    "            torchvision.models.resnet152(pretrained=True).relu,\n",
    "            torchvision.models.resnet152(pretrained=True).maxpool,\n",
    "            torchvision.models.resnet152(pretrained=True).layer1,\n",
    "            torchvision.models.resnet152(pretrained=True).layer2,\n",
    "            torchvision.models.resnet152(pretrained=True).layer3,\n",
    "            torchvision.models.resnet152(pretrained=True).layer4,\n",
    "            torchvision.models.resnet152(pretrained=True).avgpool,   \n",
    "        )\n",
    "        self.feat = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2048, 256),\n",
    "        )\n",
    "        for index,net in enumerate(self.feat):\n",
    "            if index==0 :\n",
    "                torch.nn.init.xavier_uniform_(net.weight)      \n",
    "        self.pred = torch.nn.Sequential(\n",
    "            torch.nn.Linear(256, 10),\n",
    "        )  \n",
    "        for index,net in enumerate(self.pred):\n",
    "            if index==0:\n",
    "                torch.nn.init.xavier_uniform_(net.weight)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.extract(x)    \n",
    "        x = x.view(-1, 2048)\n",
    "        feat = self.feat(x)\n",
    "        pred = F.log_softmax(self.pred(feat),1)\n",
    "        return feat ,pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. choose optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "## load model param\n",
    "checkpoint = torch.load(\"old_model/init1228.pkl\")\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "## only for finetune\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.feat.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.pred.parameters():\n",
    "    param.requires_grad = True\n",
    "## \n",
    "\n",
    "model=model.cuda()\n",
    "optimizer4nn = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "                               lr=1e-3, \n",
    "                               momentum=0.9, \n",
    "                               weight_decay=0.0005)    \n",
    "nllloss = CrossEntropyLabelSmooth(10,0.1).cuda()\n",
    "scheduler  = lr_scheduler.CosineAnnealingLR(optimizer4nn, T_max=5,eta_min=4e-08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm_notebook\n",
    "# def train(train_loader, model, epoch):\n",
    "#     print(\"Training Epoch: {}\".format(epoch))\n",
    "#     model.train()\n",
    "#     train_precision=0.0\n",
    "#     for step, (data, target) in enumerate(train_loader,1):\n",
    "#         data = Variable(data).cuda()\n",
    "#         target = Variable(target).cuda()\n",
    "#         feat, pred = model(data)\n",
    "#         _, pred_label = pred.max(dim=1)\n",
    "#         loss=nllloss(pred, target)\n",
    "#         optimizer4nn.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer4nn.step()\n",
    "#         train_precision += float(torch.sum(pred_label== target)) \n",
    "#         if step % 350 == 0:\n",
    "#             print(\"Epoch: {} step: {} loss:{}\".format(epoch, step,loss))\n",
    "            \n",
    "# #     train_precision /= 90000.0\n",
    "#     train_precision /= 160000.0\n",
    "#     print(\"train accuracy: {}%\".format(train_precision * 100))\n",
    "#     return train_precision\n",
    "            \n",
    "# def test(test_loader, model, epoch):\n",
    "#     print(\"Predicting Epoch: {}\".format(epoch))\n",
    "#     model.eval()\n",
    "#     precision=0.0\n",
    "#     for (data, target) in tqdm_notebook(test_loader):\n",
    "#         data = Variable(data).cuda()\n",
    "#         target = Variable(target).cuda()\n",
    "\n",
    "#         feature, pred = model(data)\n",
    "#         _, pred_label = pred.max(dim=1)\n",
    "        \n",
    "#         precision += float(torch.sum(pred_label == target))\n",
    "\n",
    "# #     precision /=90000.0\n",
    "#     precision /=20000.0\n",
    "#     print(\"Validation accuracy: {}%\".format(precision * 100))\n",
    "#     return precision\n",
    "# startepoch=0\n",
    "# best_precision=0.8\n",
    "# for epoch in range(startepoch,startepoch+60):\n",
    "#     train_precision=train(train_dataloader, model, epoch)\n",
    "#     precision=test(valid_dataloader, model, epoch)\n",
    "    \n",
    "#     scheduler.step()\n",
    "#     if precision>best_precision:\n",
    "#         best_precision=precision\n",
    "#         state = {\"model\":model.state_dict(),\"epoch\":epoch,\n",
    "#                  \"valid_acc\":precision,\n",
    "#                  \"train_acc\":train_precision,\n",
    "#             }\n",
    "#         PATH =\"old_model/init1228.pkl\"\n",
    "#         torch.save(state, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Evaluate your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test usage - do not modify this\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from more_itertools import chunked\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestData(ImageFolder):\n",
    "    def __getitem__(self, idx):\n",
    "        # drop labels\n",
    "        return super(TestData, self).__getitem__(idx)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use transform\n",
    "def test_tf(x):\n",
    "    im_aug = transforms.Compose([\n",
    "        transforms.Resize(120),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    x = im_aug(x)\n",
    "    return x\n",
    "\n",
    "test_datafolder = TestData(data_root[\"test\"], transform=test_tf)\n",
    "classes = np.array(test_datafolder.classes)\n",
    "imgs = [x for (x, _) in test_datafolder.imgs]\n",
    "labels = classes[[x for (_, x) in test_datafolder.imgs]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all test images from disk(SSD) into memory\n",
    "# this is expected to take minutes\n",
    "# this may fails due to system kill signal - just try it again later\n",
    "# testdata = next(iter(DataLoader(test_datafolder, batch_size=len(test_datafolder))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "\n",
    "## DO NOT USE batch_size=90000 because i do transform =test_tf\n",
    "def evaluate(model, testdata, imgs, labels, batch_size=256):\n",
    "    files_loader = [x for x in chunked(imgs, batch_size)]\n",
    "    test_dataloader = DataLoader(testdata, batch_size=batch_size)\n",
    "    groundtruth_loader = chunked(labels, batch_size)\n",
    "    num_batches = len(files_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    columns = [\"file\", \"prediction\", \"ground_truth\"]\n",
    "    data_iter = iter(zip(test_dataloader, files_loader, groundtruth_loader))\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for _ in tqdm_notebook(range(num_batches)):\n",
    "        X, filepath, Y = next(data_iter)\n",
    "        X=X.cuda()\n",
    "        with torch.no_grad():\n",
    "            idx = torch.argmax(model(X)[1], 1).cpu()\n",
    "        prediction = classes[idx]\n",
    "        buffer = pd.DataFrame(zip(filepath, prediction, Y), columns=columns)\n",
    "        df = df.append(buffer)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52699d1719474402901166d1f9852fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=352), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>prediction</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>test/airplane/cifar10-test-10.png</td>\n",
       "      <td>airplane</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>test/airplane/cifar10-test-1001.png</td>\n",
       "      <td>airplane</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>test/airplane/cifar10-test-1010.png</td>\n",
       "      <td>airplane</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>test/airplane/cifar10-test-1018.png</td>\n",
       "      <td>airplane</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>test/airplane/cifar10-test-1022.png</td>\n",
       "      <td>airplane</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>test/truck/n04520170_9909.png</td>\n",
       "      <td>truck</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>test/truck/n04520170_9936.png</td>\n",
       "      <td>truck</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>test/truck/n04520170_9942.png</td>\n",
       "      <td>truck</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>test/truck/n04520170_9963.png</td>\n",
       "      <td>truck</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>test/truck/n04520170_9989.png</td>\n",
       "      <td>truck</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    file prediction ground_truth\n",
       "0      test/airplane/cifar10-test-10.png   airplane     airplane\n",
       "1    test/airplane/cifar10-test-1001.png   airplane     airplane\n",
       "2    test/airplane/cifar10-test-1010.png   airplane     airplane\n",
       "3    test/airplane/cifar10-test-1018.png   airplane     airplane\n",
       "4    test/airplane/cifar10-test-1022.png   airplane     airplane\n",
       "..                                   ...        ...          ...\n",
       "139        test/truck/n04520170_9909.png      truck        truck\n",
       "140        test/truck/n04520170_9936.png      truck        truck\n",
       "141        test/truck/n04520170_9942.png      truck        truck\n",
       "142        test/truck/n04520170_9963.png      truck        truck\n",
       "143        test/truck/n04520170_9989.png      truck        truck\n",
       "\n",
       "[90000 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = evaluate(model, test_datafolder, imgs, labels)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check your model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 91.251%\n"
     ]
    }
   ],
   "source": [
    "accu = np.sum(df[\"ground_truth\"] == df[\"prediction\"])/float(len(df)) * 100\n",
    "print(f\"Accuracy {accu:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "restart your kernel to free GPU resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Course",
   "language": "python",
   "name": "ai-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
